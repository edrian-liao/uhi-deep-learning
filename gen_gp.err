2025-04-14 10:14:54,527 - INFO - Logging initialized for city: Albuquerque
2025-04-14 10:14:55,252 - INFO - Using device: cuda
2025-04-14 10:14:55,254 - INFO - 
Fold 1/4
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_x = torch.tensor(X[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_y = torch.tensor(y[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_x = torch.tensor(X[val_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_y = torch.tensor(y[val_index], dtype=torch.float32).to(device)
2025-04-14 10:15:00,549 - INFO - Epoch 1/60 - Loss: 1.4974
2025-04-14 10:15:00,625 - INFO - Epoch 2/60 - Loss: 1.4783
2025-04-14 10:15:00,702 - INFO - Epoch 3/60 - Loss: 1.4633
2025-04-14 10:15:00,777 - INFO - Epoch 4/60 - Loss: 1.4524
2025-04-14 10:15:00,854 - INFO - Epoch 5/60 - Loss: 1.4441
2025-04-14 10:15:00,932 - INFO - Epoch 6/60 - Loss: 1.4385
2025-04-14 10:15:01,012 - INFO - Epoch 7/60 - Loss: 1.4343
2025-04-14 10:15:01,093 - INFO - Epoch 8/60 - Loss: 1.4314
2025-04-14 10:15:01,172 - INFO - Epoch 9/60 - Loss: 1.4292
2025-04-14 10:15:01,254 - INFO - Epoch 10/60 - Loss: 1.4271
2025-04-14 10:15:01,332 - INFO - Epoch 11/60 - Loss: 1.4247
2025-04-14 10:15:01,412 - INFO - Epoch 12/60 - Loss: 1.4215
2025-04-14 10:15:01,495 - INFO - Epoch 13/60 - Loss: 1.4183
2025-04-14 10:15:01,581 - INFO - Epoch 14/60 - Loss: 1.4131
2025-04-14 10:15:01,671 - INFO - Epoch 15/60 - Loss: 1.4079
2025-04-14 10:15:01,760 - INFO - Epoch 16/60 - Loss: 1.4028
2025-04-14 10:15:01,843 - INFO - Epoch 17/60 - Loss: 1.3943
2025-04-14 10:15:01,923 - INFO - Epoch 18/60 - Loss: 1.3892
2025-04-14 10:15:01,997 - INFO - Epoch 19/60 - Loss: 1.3807
2025-04-14 10:15:02,069 - INFO - Epoch 20/60 - Loss: 1.3736
2025-04-14 10:15:02,144 - INFO - Epoch 21/60 - Loss: 1.3659
2025-04-14 10:15:02,217 - INFO - Epoch 22/60 - Loss: 1.3570
2025-04-14 10:15:02,293 - INFO - Epoch 23/60 - Loss: 1.3486
2025-04-14 10:15:02,366 - INFO - Epoch 24/60 - Loss: 1.3383
2025-04-14 10:15:02,443 - INFO - Epoch 25/60 - Loss: 1.3222
2025-04-14 10:15:02,515 - INFO - Epoch 26/60 - Loss: 1.3080
2025-04-14 10:15:02,588 - INFO - Epoch 27/60 - Loss: 1.2872
2025-04-14 10:15:02,663 - INFO - Epoch 28/60 - Loss: 1.2625
2025-04-14 10:15:02,736 - INFO - Epoch 29/60 - Loss: 1.2397
2025-04-14 10:15:02,813 - INFO - Epoch 30/60 - Loss: 1.2116
2025-04-14 10:15:02,886 - INFO - Epoch 31/60 - Loss: 1.1890
2025-04-14 10:15:02,962 - INFO - Epoch 32/60 - Loss: 1.1658
2025-04-14 10:15:03,035 - INFO - Epoch 33/60 - Loss: 1.1429
2025-04-14 10:15:03,114 - INFO - Epoch 34/60 - Loss: 1.1328
2025-04-14 10:15:03,193 - INFO - Epoch 35/60 - Loss: 1.1162
2025-04-14 10:15:03,273 - INFO - Epoch 36/60 - Loss: 1.1163
2025-04-14 10:15:03,352 - INFO - Epoch 37/60 - Loss: 1.1114
2025-04-14 10:15:03,432 - INFO - Epoch 38/60 - Loss: 1.1122
2025-04-14 10:15:03,512 - INFO - Epoch 39/60 - Loss: 1.1172
2025-04-14 10:15:03,591 - INFO - Epoch 40/60 - Loss: 1.1251
2025-04-14 10:15:03,666 - INFO - Epoch 41/60 - Loss: 1.1379
2025-04-14 10:15:03,739 - INFO - Epoch 42/60 - Loss: 1.1364
2025-04-14 10:15:03,814 - INFO - Epoch 43/60 - Loss: 1.1488
2025-04-14 10:15:03,888 - INFO - Epoch 44/60 - Loss: 1.1498
2025-04-14 10:15:03,963 - INFO - Epoch 45/60 - Loss: 1.1608
2025-04-14 10:15:04,035 - INFO - Epoch 46/60 - Loss: 1.1559
2025-04-14 10:15:04,109 - INFO - Epoch 47/60 - Loss: 1.1708
2025-04-14 10:15:04,182 - INFO - Epoch 48/60 - Loss: 1.1651
2025-04-14 10:15:04,255 - INFO - Epoch 49/60 - Loss: 1.1661
2025-04-14 10:15:04,327 - INFO - Epoch 50/60 - Loss: 1.1699
2025-04-14 10:15:04,400 - INFO - Epoch 51/60 - Loss: 1.1718
2025-04-14 10:15:04,473 - INFO - Epoch 52/60 - Loss: 1.1734
2025-04-14 10:15:04,545 - INFO - Epoch 53/60 - Loss: 1.1654
2025-04-14 10:15:04,619 - INFO - Epoch 54/60 - Loss: 1.1654
2025-04-14 10:15:04,691 - INFO - Epoch 55/60 - Loss: 1.1596
2025-04-14 10:15:04,765 - INFO - Epoch 56/60 - Loss: 1.1530
2025-04-14 10:15:04,838 - INFO - Epoch 57/60 - Loss: 1.1495
2025-04-14 10:15:04,911 - INFO - Epoch 58/60 - Loss: 1.1501
2025-04-14 10:15:04,983 - INFO - Epoch 59/60 - Loss: 1.1403
2025-04-14 10:15:05,057 - INFO - Epoch 60/60 - Loss: 1.1411
2025-04-14 10:15:05,191 - INFO - Validation R² (Fold 1): 0.6891
2025-04-14 10:15:05,191 - INFO - 
Fold 2/4
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_x = torch.tensor(X[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_y = torch.tensor(y[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_x = torch.tensor(X[val_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_y = torch.tensor(y[val_index], dtype=torch.float32).to(device)
2025-04-14 10:15:05,313 - INFO - Epoch 1/60 - Loss: 1.4635
2025-04-14 10:15:05,411 - INFO - Epoch 2/60 - Loss: 1.4471
2025-04-14 10:15:05,483 - INFO - Epoch 3/60 - Loss: 1.4345
2025-04-14 10:15:05,561 - INFO - Epoch 4/60 - Loss: 1.4254
2025-04-14 10:15:05,642 - INFO - Epoch 5/60 - Loss: 1.4194
2025-04-14 10:15:05,721 - INFO - Epoch 6/60 - Loss: 1.4151
2025-04-14 10:15:05,811 - INFO - Epoch 7/60 - Loss: 1.4124
2025-04-14 10:15:05,890 - INFO - Epoch 8/60 - Loss: 1.4104
2025-04-14 10:15:05,972 - INFO - Epoch 9/60 - Loss: 1.4089
2025-04-14 10:15:06,052 - INFO - Epoch 10/60 - Loss: 1.4058
2025-04-14 10:15:06,132 - INFO - Epoch 11/60 - Loss: 1.4038
2025-04-14 10:15:06,211 - INFO - Epoch 12/60 - Loss: 1.3996
2025-04-14 10:15:06,292 - INFO - Epoch 13/60 - Loss: 1.3957
2025-04-14 10:15:06,372 - INFO - Epoch 14/60 - Loss: 1.3890
2025-04-14 10:15:06,451 - INFO - Epoch 15/60 - Loss: 1.3834
2025-04-14 10:15:06,532 - INFO - Epoch 16/60 - Loss: 1.3760
2025-04-14 10:15:06,612 - INFO - Epoch 17/60 - Loss: 1.3696
2025-04-14 10:15:06,691 - INFO - Epoch 18/60 - Loss: 1.3621
2025-04-14 10:15:06,772 - INFO - Epoch 19/60 - Loss: 1.3531
2025-04-14 10:15:06,852 - INFO - Epoch 20/60 - Loss: 1.3461
2025-04-14 10:15:06,931 - INFO - Epoch 21/60 - Loss: 1.3374
2025-04-14 10:15:07,012 - INFO - Epoch 22/60 - Loss: 1.3287
2025-04-14 10:15:07,091 - INFO - Epoch 23/60 - Loss: 1.3156
2025-04-14 10:15:07,173 - INFO - Epoch 24/60 - Loss: 1.3023
2025-04-14 10:15:07,252 - INFO - Epoch 25/60 - Loss: 1.2871
2025-04-14 10:15:07,330 - INFO - Epoch 26/60 - Loss: 1.2639
2025-04-14 10:15:07,407 - INFO - Epoch 27/60 - Loss: 1.2427
2025-04-14 10:15:07,483 - INFO - Epoch 28/60 - Loss: 1.2124
2025-04-14 10:15:07,562 - INFO - Epoch 29/60 - Loss: 1.1792
2025-04-14 10:15:07,643 - INFO - Epoch 30/60 - Loss: 1.1518
2025-04-14 10:15:07,722 - INFO - Epoch 31/60 - Loss: 1.1227
2025-04-14 10:15:07,803 - INFO - Epoch 32/60 - Loss: 1.0909
2025-04-14 10:15:07,883 - INFO - Epoch 33/60 - Loss: 1.0656
2025-04-14 10:15:07,962 - INFO - Epoch 34/60 - Loss: 1.0538
2025-04-14 10:15:08,043 - INFO - Epoch 35/60 - Loss: 1.0412
2025-04-14 10:15:08,122 - INFO - Epoch 36/60 - Loss: 1.0378
2025-04-14 10:15:08,203 - INFO - Epoch 37/60 - Loss: 1.0281
2025-04-14 10:15:08,282 - INFO - Epoch 38/60 - Loss: 1.0387
2025-04-14 10:15:08,362 - INFO - Epoch 39/60 - Loss: 1.0481
2025-04-14 10:15:08,442 - INFO - Epoch 40/60 - Loss: 1.0643
2025-04-14 10:15:08,523 - INFO - Epoch 41/60 - Loss: 1.0698
2025-04-14 10:15:08,603 - INFO - Epoch 42/60 - Loss: 1.0886
2025-04-14 10:15:08,683 - INFO - Epoch 43/60 - Loss: 1.0955
2025-04-14 10:15:08,763 - INFO - Epoch 44/60 - Loss: 1.1144
2025-04-14 10:15:08,842 - INFO - Epoch 45/60 - Loss: 1.1123
2025-04-14 10:15:08,922 - INFO - Epoch 46/60 - Loss: 1.1285
2025-04-14 10:15:09,002 - INFO - Epoch 47/60 - Loss: 1.1313
2025-04-14 10:15:09,083 - INFO - Epoch 48/60 - Loss: 1.1495
2025-04-14 10:15:09,163 - INFO - Epoch 49/60 - Loss: 1.1435
2025-04-14 10:15:09,242 - INFO - Epoch 50/60 - Loss: 1.1434
2025-04-14 10:15:09,323 - INFO - Epoch 51/60 - Loss: 1.1495
2025-04-14 10:15:09,403 - INFO - Epoch 52/60 - Loss: 1.1412
2025-04-14 10:15:09,482 - INFO - Epoch 53/60 - Loss: 1.1240
2025-04-14 10:15:09,563 - INFO - Epoch 54/60 - Loss: 1.1163
2025-04-14 10:15:09,643 - INFO - Epoch 55/60 - Loss: 1.1132
2025-04-14 10:15:09,722 - INFO - Epoch 56/60 - Loss: 1.1101
2025-04-14 10:15:09,802 - INFO - Epoch 57/60 - Loss: 1.0973
2025-04-14 10:15:09,882 - INFO - Epoch 58/60 - Loss: 1.0874
2025-04-14 10:15:11,151 - INFO - Epoch 59/60 - Loss: 1.0770
2025-04-14 10:15:11,232 - INFO - Epoch 60/60 - Loss: 1.0745
2025-04-14 10:15:11,352 - INFO - Validation R² (Fold 2): 0.6396
2025-04-14 10:15:11,353 - INFO - 
Fold 3/4
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_x = torch.tensor(X[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_y = torch.tensor(y[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_x = torch.tensor(X[val_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_y = torch.tensor(y[val_index], dtype=torch.float32).to(device)
2025-04-14 10:15:11,440 - INFO - Epoch 1/60 - Loss: 1.4726
2025-04-14 10:15:11,521 - INFO - Epoch 2/60 - Loss: 1.4553
2025-04-14 10:15:11,612 - INFO - Epoch 3/60 - Loss: 1.4420
2025-04-14 10:15:11,689 - INFO - Epoch 4/60 - Loss: 1.4322
2025-04-14 10:15:11,762 - INFO - Epoch 5/60 - Loss: 1.4252
2025-04-14 10:15:11,839 - INFO - Epoch 6/60 - Loss: 1.4205
2025-04-14 10:15:11,919 - INFO - Epoch 7/60 - Loss: 1.4174
2025-04-14 10:15:11,998 - INFO - Epoch 8/60 - Loss: 1.4147
2025-04-14 10:15:12,079 - INFO - Epoch 9/60 - Loss: 1.4130
2025-04-14 10:15:12,159 - INFO - Epoch 10/60 - Loss: 1.4100
2025-04-14 10:15:12,239 - INFO - Epoch 11/60 - Loss: 1.4075
2025-04-14 10:15:12,320 - INFO - Epoch 12/60 - Loss: 1.4051
2025-04-14 10:15:12,400 - INFO - Epoch 13/60 - Loss: 1.4001
2025-04-14 10:15:12,480 - INFO - Epoch 14/60 - Loss: 1.3939
2025-04-14 10:15:12,561 - INFO - Epoch 15/60 - Loss: 1.3895
2025-04-14 10:15:12,641 - INFO - Epoch 16/60 - Loss: 1.3823
2025-04-14 10:15:12,720 - INFO - Epoch 17/60 - Loss: 1.3744
2025-04-14 10:15:12,800 - INFO - Epoch 18/60 - Loss: 1.3687
2025-04-14 10:15:12,880 - INFO - Epoch 19/60 - Loss: 1.3615
2025-04-14 10:15:12,958 - INFO - Epoch 20/60 - Loss: 1.3553
2025-04-14 10:15:13,039 - INFO - Epoch 21/60 - Loss: 1.3483
2025-04-14 10:15:13,120 - INFO - Epoch 22/60 - Loss: 1.3427
2025-04-14 10:15:13,200 - INFO - Epoch 23/60 - Loss: 1.3301
2025-04-14 10:15:13,280 - INFO - Epoch 24/60 - Loss: 1.3204
2025-04-14 10:15:13,360 - INFO - Epoch 25/60 - Loss: 1.3025
2025-04-14 10:15:13,440 - INFO - Epoch 26/60 - Loss: 1.2866
2025-04-14 10:15:13,520 - INFO - Epoch 27/60 - Loss: 1.2639
2025-04-14 10:15:13,600 - INFO - Epoch 28/60 - Loss: 1.2395
2025-04-14 10:15:13,673 - INFO - Epoch 29/60 - Loss: 1.2118
2025-04-14 10:15:13,751 - INFO - Epoch 30/60 - Loss: 1.1866
2025-04-14 10:15:13,830 - INFO - Epoch 31/60 - Loss: 1.1648
2025-04-14 10:15:13,910 - INFO - Epoch 32/60 - Loss: 1.1365
2025-04-14 10:15:13,988 - INFO - Epoch 33/60 - Loss: 1.1114
2025-04-14 10:15:14,069 - INFO - Epoch 34/60 - Loss: 1.0950
2025-04-14 10:15:14,149 - INFO - Epoch 35/60 - Loss: 1.0890
2025-04-14 10:15:14,230 - INFO - Epoch 36/60 - Loss: 1.0806
2025-04-14 10:15:14,310 - INFO - Epoch 37/60 - Loss: 1.0825
2025-04-14 10:15:14,390 - INFO - Epoch 38/60 - Loss: 1.0799
2025-04-14 10:15:14,470 - INFO - Epoch 39/60 - Loss: 1.0873
2025-04-14 10:15:14,550 - INFO - Epoch 40/60 - Loss: 1.1079
2025-04-14 10:15:14,630 - INFO - Epoch 41/60 - Loss: 1.1024
2025-04-14 10:15:14,710 - INFO - Epoch 42/60 - Loss: 1.1210
2025-04-14 10:15:14,790 - INFO - Epoch 43/60 - Loss: 1.1288
2025-04-14 10:15:14,871 - INFO - Epoch 44/60 - Loss: 1.1443
2025-04-14 10:15:14,950 - INFO - Epoch 45/60 - Loss: 1.1517
2025-04-14 10:15:15,031 - INFO - Epoch 46/60 - Loss: 1.1578
2025-04-14 10:15:15,110 - INFO - Epoch 47/60 - Loss: 1.1649
2025-04-14 10:15:15,192 - INFO - Epoch 48/60 - Loss: 1.1705
2025-04-14 10:15:15,271 - INFO - Epoch 49/60 - Loss: 1.1577
2025-04-14 10:15:15,351 - INFO - Epoch 50/60 - Loss: 1.1585
2025-04-14 10:15:15,431 - INFO - Epoch 51/60 - Loss: 1.1546
2025-04-14 10:15:15,511 - INFO - Epoch 52/60 - Loss: 1.1486
2025-04-14 10:15:15,586 - INFO - Epoch 53/60 - Loss: 1.1441
2025-04-14 10:15:15,659 - INFO - Epoch 54/60 - Loss: 1.1443
2025-04-14 10:15:15,733 - INFO - Epoch 55/60 - Loss: 1.1342
2025-04-14 10:15:15,807 - INFO - Epoch 56/60 - Loss: 1.1271
2025-04-14 10:15:15,880 - INFO - Epoch 57/60 - Loss: 1.1201
2025-04-14 10:15:15,955 - INFO - Epoch 58/60 - Loss: 1.1099
2025-04-14 10:15:16,032 - INFO - Epoch 59/60 - Loss: 1.1113
2025-04-14 10:15:16,105 - INFO - Epoch 60/60 - Loss: 1.1009
2025-04-14 10:15:16,222 - INFO - Validation R² (Fold 3): 0.6826
2025-04-14 10:15:16,223 - INFO - 
Fold 4/4
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_x = torch.tensor(X[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_y = torch.tensor(y[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_x = torch.tensor(X[val_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_y = torch.tensor(y[val_index], dtype=torch.float32).to(device)
2025-04-14 10:15:16,310 - INFO - Epoch 1/60 - Loss: 1.4756
2025-04-14 10:15:16,387 - INFO - Epoch 2/60 - Loss: 1.4583
2025-04-14 10:15:16,462 - INFO - Epoch 3/60 - Loss: 1.4449
2025-04-14 10:15:16,539 - INFO - Epoch 4/60 - Loss: 1.4350
2025-04-14 10:15:16,614 - INFO - Epoch 5/60 - Loss: 1.4283
2025-04-14 10:15:16,690 - INFO - Epoch 6/60 - Loss: 1.4233
2025-04-14 10:15:16,764 - INFO - Epoch 7/60 - Loss: 1.4206
2025-04-14 10:15:16,841 - INFO - Epoch 8/60 - Loss: 1.4182
2025-04-14 10:15:16,919 - INFO - Epoch 9/60 - Loss: 1.4159
2025-04-14 10:15:16,994 - INFO - Epoch 10/60 - Loss: 1.4139
2025-04-14 10:15:17,071 - INFO - Epoch 11/60 - Loss: 1.4119
2025-04-14 10:15:17,151 - INFO - Epoch 12/60 - Loss: 1.4092
2025-04-14 10:15:17,230 - INFO - Epoch 13/60 - Loss: 1.4057
2025-04-14 10:15:17,310 - INFO - Epoch 14/60 - Loss: 1.4020
2025-04-14 10:15:17,390 - INFO - Epoch 15/60 - Loss: 1.3961
2025-04-14 10:15:17,470 - INFO - Epoch 16/60 - Loss: 1.3915
2025-04-14 10:15:17,550 - INFO - Epoch 17/60 - Loss: 1.3865
2025-04-14 10:15:17,631 - INFO - Epoch 18/60 - Loss: 1.3807
2025-04-14 10:15:17,712 - INFO - Epoch 19/60 - Loss: 1.3752
2025-04-14 10:15:17,791 - INFO - Epoch 20/60 - Loss: 1.3683
2025-04-14 10:15:17,870 - INFO - Epoch 21/60 - Loss: 1.3647
2025-04-14 10:15:17,944 - INFO - Epoch 22/60 - Loss: 1.3563
2025-04-14 10:15:18,025 - INFO - Epoch 23/60 - Loss: 1.3478
2025-04-14 10:15:18,102 - INFO - Epoch 24/60 - Loss: 1.3358
2025-04-14 10:15:18,181 - INFO - Epoch 25/60 - Loss: 1.3258
2025-04-14 10:15:18,260 - INFO - Epoch 26/60 - Loss: 1.3116
2025-04-14 10:15:18,335 - INFO - Epoch 27/60 - Loss: 1.2930
2025-04-14 10:15:18,412 - INFO - Epoch 28/60 - Loss: 1.2706
2025-04-14 10:15:18,490 - INFO - Epoch 29/60 - Loss: 1.2447
2025-04-14 10:15:18,565 - INFO - Epoch 30/60 - Loss: 1.2192
2025-04-14 10:15:18,642 - INFO - Epoch 31/60 - Loss: 1.1969
2025-04-14 10:15:18,720 - INFO - Epoch 32/60 - Loss: 1.1708
2025-04-14 10:15:18,799 - INFO - Epoch 33/60 - Loss: 1.1492
2025-04-14 10:15:18,879 - INFO - Epoch 34/60 - Loss: 1.1317
2025-04-14 10:15:18,955 - INFO - Epoch 35/60 - Loss: 1.1226
2025-04-14 10:15:19,032 - INFO - Epoch 36/60 - Loss: 1.1091
2025-04-14 10:15:19,111 - INFO - Epoch 37/60 - Loss: 1.1005
2025-04-14 10:15:19,191 - INFO - Epoch 38/60 - Loss: 1.0942
2025-04-14 10:15:19,271 - INFO - Epoch 39/60 - Loss: 1.0987
2025-04-14 10:15:19,351 - INFO - Epoch 40/60 - Loss: 1.1032
2025-04-14 10:15:19,430 - INFO - Epoch 41/60 - Loss: 1.1091
2025-04-14 10:15:19,510 - INFO - Epoch 42/60 - Loss: 1.1177
2025-04-14 10:15:19,589 - INFO - Epoch 43/60 - Loss: 1.1286
2025-04-14 10:15:19,665 - INFO - Epoch 44/60 - Loss: 1.1504
2025-04-14 10:15:19,742 - INFO - Epoch 45/60 - Loss: 1.1501
2025-04-14 10:15:19,821 - INFO - Epoch 46/60 - Loss: 1.1468
2025-04-14 10:15:19,901 - INFO - Epoch 47/60 - Loss: 1.1611
2025-04-14 10:15:19,978 - INFO - Epoch 48/60 - Loss: 1.1503
2025-04-14 10:15:20,061 - INFO - Epoch 49/60 - Loss: 1.1616
2025-04-14 10:15:20,141 - INFO - Epoch 50/60 - Loss: 1.1661
2025-04-14 10:15:20,221 - INFO - Epoch 51/60 - Loss: 1.1617
2025-04-14 10:15:20,301 - INFO - Epoch 52/60 - Loss: 1.1726
2025-04-14 10:15:20,381 - INFO - Epoch 53/60 - Loss: 1.1583
2025-04-14 10:15:20,461 - INFO - Epoch 54/60 - Loss: 1.1588
2025-04-14 10:15:20,541 - INFO - Epoch 55/60 - Loss: 1.1635
2025-04-14 10:15:20,622 - INFO - Epoch 56/60 - Loss: 1.1532
2025-04-14 10:15:20,702 - INFO - Epoch 57/60 - Loss: 1.1461
2025-04-14 10:15:20,780 - INFO - Epoch 58/60 - Loss: 1.1478
2025-04-14 10:15:20,859 - INFO - Epoch 59/60 - Loss: 1.1348
2025-04-14 10:15:20,940 - INFO - Epoch 60/60 - Loss: 1.1306
2025-04-14 10:15:21,054 - INFO - Validation R² (Fold 4): 0.6920
2025-04-14 10:15:21,054 - INFO - 
Average R² across folds: 0.6758
2025-04-14 10:15:21,054 - INFO - Best R² across folds: 0.6920
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  final_model = best_fold_model(torch.tensor(X, dtype=torch.float32).to(device),
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(y, dtype=torch.float32).to(device),
2025-04-14 10:15:21,057 - INFO - 

2025-04-14 10:15:21,057 - INFO - 
Fold 1/4
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_x = torch.tensor(X[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_y = torch.tensor(y[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_x = torch.tensor(X[val_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_y = torch.tensor(y[val_index], dtype=torch.float32).to(device)
2025-04-14 10:15:21,141 - INFO - Epoch 1/50 - Loss: 1.4802
2025-04-14 10:15:21,240 - INFO - Epoch 2/50 - Loss: 1.4476
2025-04-14 10:15:21,326 - INFO - Epoch 3/50 - Loss: 1.4238
2025-04-14 10:15:21,405 - INFO - Epoch 4/50 - Loss: 1.4067
2025-04-14 10:15:21,484 - INFO - Epoch 5/50 - Loss: 1.3946
2025-04-14 10:15:21,564 - INFO - Epoch 6/50 - Loss: 1.3862
2025-04-14 10:15:21,643 - INFO - Epoch 7/50 - Loss: 1.3797
2025-04-14 10:15:21,723 - INFO - Epoch 8/50 - Loss: 1.3744
2025-04-14 10:15:21,804 - INFO - Epoch 9/50 - Loss: 1.3683
2025-04-14 10:15:21,883 - INFO - Epoch 10/50 - Loss: 1.3629
2025-04-14 10:15:21,963 - INFO - Epoch 11/50 - Loss: 1.3575
2025-04-14 10:15:22,043 - INFO - Epoch 12/50 - Loss: 1.3467
2025-04-14 10:15:22,123 - INFO - Epoch 13/50 - Loss: 1.3365
2025-04-14 10:15:22,203 - INFO - Epoch 14/50 - Loss: 1.3167
2025-04-14 10:15:22,282 - INFO - Epoch 15/50 - Loss: 1.2900
2025-04-14 10:15:22,363 - INFO - Epoch 16/50 - Loss: 1.2733
2025-04-14 10:15:22,442 - INFO - Epoch 17/50 - Loss: 1.2362
2025-04-14 10:15:22,522 - INFO - Epoch 18/50 - Loss: 1.1992
2025-04-14 10:15:22,603 - INFO - Epoch 19/50 - Loss: 1.1606
2025-04-14 10:15:22,695 - INFO - Epoch 20/50 - Loss: 1.1741
2025-04-14 10:15:22,794 - INFO - Epoch 21/50 - Loss: 1.1814
2025-04-14 10:15:22,902 - INFO - Epoch 22/50 - Loss: 1.1720
2025-04-14 10:15:23,024 - INFO - Epoch 23/50 - Loss: 1.2277
2025-04-14 10:15:23,136 - INFO - Epoch 24/50 - Loss: 1.2040
2025-04-14 10:15:23,256 - INFO - Epoch 25/50 - Loss: 1.2512
2025-04-14 10:15:23,394 - INFO - Epoch 26/50 - Loss: 1.3000
2025-04-14 10:15:23,543 - INFO - Epoch 27/50 - Loss: 1.3655
2025-04-14 10:15:23,697 - INFO - Epoch 28/50 - Loss: 1.4171
2025-04-14 10:15:23,858 - INFO - Epoch 29/50 - Loss: 1.4278
2025-04-14 10:15:24,017 - INFO - Epoch 30/50 - Loss: 1.4694
2025-04-14 10:15:24,204 - INFO - Epoch 31/50 - Loss: 1.5305
2025-04-14 10:15:24,384 - INFO - Epoch 32/50 - Loss: 1.5410
2025-04-14 10:15:24,556 - INFO - Epoch 33/50 - Loss: 1.5647
2025-04-14 10:15:24,735 - INFO - Epoch 34/50 - Loss: 1.6098
2025-04-14 10:15:24,918 - INFO - Epoch 35/50 - Loss: 1.6400
2025-04-14 10:15:25,096 - INFO - Epoch 36/50 - Loss: 1.6473
2025-04-14 10:15:25,283 - INFO - Epoch 37/50 - Loss: 1.6816
2025-04-14 10:15:25,498 - INFO - Epoch 38/50 - Loss: 1.7558
2025-04-14 10:15:25,711 - INFO - Epoch 39/50 - Loss: 1.7682
2025-04-14 10:15:25,926 - INFO - Epoch 40/50 - Loss: 1.7901
2025-04-14 10:15:26,143 - INFO - Epoch 41/50 - Loss: 1.7818
2025-04-14 10:15:26,353 - INFO - Epoch 42/50 - Loss: 1.7838
2025-04-14 10:15:26,566 - INFO - Epoch 43/50 - Loss: 1.8219
2025-04-14 10:15:26,776 - INFO - Epoch 44/50 - Loss: 1.7982
2025-04-14 10:15:26,997 - INFO - Epoch 45/50 - Loss: 1.8159
2025-04-14 10:15:27,202 - INFO - Epoch 46/50 - Loss: 1.7960
2025-04-14 10:15:27,416 - INFO - Epoch 47/50 - Loss: 1.8274
2025-04-14 10:15:27,615 - INFO - Epoch 48/50 - Loss: 1.8147
2025-04-14 10:15:27,816 - INFO - Epoch 49/50 - Loss: 1.8247
2025-04-14 10:15:28,025 - INFO - Epoch 50/50 - Loss: 1.8253
2025-04-14 10:15:28,438 - INFO - Validation R² (Fold 1): 0.4908
2025-04-14 10:15:28,439 - INFO - 
Fold 2/4
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_x = torch.tensor(X[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_y = torch.tensor(y[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_x = torch.tensor(X[val_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_y = torch.tensor(y[val_index], dtype=torch.float32).to(device)
2025-04-14 10:15:28,552 - INFO - Epoch 1/50 - Loss: 1.4760
2025-04-14 10:15:28,653 - INFO - Epoch 2/50 - Loss: 1.4372
2025-04-14 10:15:28,731 - INFO - Epoch 3/50 - Loss: 1.4125
2025-04-14 10:15:28,812 - INFO - Epoch 4/50 - Loss: 1.3955
2025-04-14 10:15:28,887 - INFO - Epoch 5/50 - Loss: 1.3843
2025-04-14 10:15:28,963 - INFO - Epoch 6/50 - Loss: 1.3741
2025-04-14 10:15:29,042 - INFO - Epoch 7/50 - Loss: 1.3686
2025-04-14 10:15:29,124 - INFO - Epoch 8/50 - Loss: 1.3614
2025-04-14 10:15:29,203 - INFO - Epoch 9/50 - Loss: 1.3559
2025-04-14 10:15:29,283 - INFO - Epoch 10/50 - Loss: 1.3505
2025-04-14 10:15:29,363 - INFO - Epoch 11/50 - Loss: 1.3430
2025-04-14 10:15:29,443 - INFO - Epoch 12/50 - Loss: 1.3332
2025-04-14 10:15:29,523 - INFO - Epoch 13/50 - Loss: 1.3195
2025-04-14 10:15:29,603 - INFO - Epoch 14/50 - Loss: 1.3084
2025-04-14 10:15:29,683 - INFO - Epoch 15/50 - Loss: 1.2840
2025-04-14 10:15:29,763 - INFO - Epoch 16/50 - Loss: 1.2590
2025-04-14 10:15:29,844 - INFO - Epoch 17/50 - Loss: 1.2255
2025-04-14 10:15:29,923 - INFO - Epoch 18/50 - Loss: 1.1805
2025-04-14 10:15:30,004 - INFO - Epoch 19/50 - Loss: 1.1429
2025-04-14 10:15:30,086 - INFO - Epoch 20/50 - Loss: 1.1212
2025-04-14 10:15:30,171 - INFO - Epoch 21/50 - Loss: 1.1083
2025-04-14 10:15:30,266 - INFO - Epoch 22/50 - Loss: 1.1033
2025-04-14 10:15:30,366 - INFO - Epoch 23/50 - Loss: 1.1231
2025-04-14 10:15:30,472 - INFO - Epoch 24/50 - Loss: 1.1377
2025-04-14 10:15:30,594 - INFO - Epoch 25/50 - Loss: 1.1778
2025-04-14 10:15:30,725 - INFO - Epoch 26/50 - Loss: 1.2032
2025-04-14 10:15:30,856 - INFO - Epoch 27/50 - Loss: 1.2277
2025-04-14 10:15:30,994 - INFO - Epoch 28/50 - Loss: 1.2667
2025-04-14 10:15:31,135 - INFO - Epoch 29/50 - Loss: 1.2917
2025-04-14 10:15:31,286 - INFO - Epoch 30/50 - Loss: 1.3450
2025-04-14 10:15:31,433 - INFO - Epoch 31/50 - Loss: 1.3661
2025-04-14 10:15:31,585 - INFO - Epoch 32/50 - Loss: 1.3924
2025-04-14 10:15:31,751 - INFO - Epoch 33/50 - Loss: 1.4315
2025-04-14 10:15:31,931 - INFO - Epoch 34/50 - Loss: 1.5164
2025-04-14 10:15:32,111 - INFO - Epoch 35/50 - Loss: 1.5302
2025-04-14 10:15:32,294 - INFO - Epoch 36/50 - Loss: 1.5540
2025-04-14 10:15:32,471 - INFO - Epoch 37/50 - Loss: 1.5620
2025-04-14 10:15:32,653 - INFO - Epoch 38/50 - Loss: 1.5680
2025-04-14 10:15:32,833 - INFO - Epoch 39/50 - Loss: 1.5917
2025-04-14 10:15:33,013 - INFO - Epoch 40/50 - Loss: 1.6022
2025-04-14 10:15:33,206 - INFO - Epoch 41/50 - Loss: 1.6750
2025-04-14 10:15:33,397 - INFO - Epoch 42/50 - Loss: 1.6798
2025-04-14 10:15:33,595 - INFO - Epoch 43/50 - Loss: 1.7028
2025-04-14 10:15:33,786 - INFO - Epoch 44/50 - Loss: 1.7025
2025-04-14 10:15:33,956 - INFO - Epoch 45/50 - Loss: 1.6513
2025-04-14 10:15:34,152 - INFO - Epoch 46/50 - Loss: 1.7223
2025-04-14 10:15:34,335 - INFO - Epoch 47/50 - Loss: 1.7028
2025-04-14 10:15:34,535 - INFO - Epoch 48/50 - Loss: 1.7725
2025-04-14 10:15:34,732 - INFO - Epoch 49/50 - Loss: 1.7739
2025-04-14 10:15:34,917 - INFO - Epoch 50/50 - Loss: 1.7750
2025-04-14 10:15:35,345 - INFO - Validation R² (Fold 2): 0.6144
2025-04-14 10:15:35,345 - INFO - 
Fold 3/4
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_x = torch.tensor(X[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_y = torch.tensor(y[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_x = torch.tensor(X[val_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_y = torch.tensor(y[val_index], dtype=torch.float32).to(device)
2025-04-14 10:15:35,431 - INFO - Epoch 1/50 - Loss: 1.4600
2025-04-14 10:15:35,533 - INFO - Epoch 2/50 - Loss: 1.4274
2025-04-14 10:15:35,612 - INFO - Epoch 3/50 - Loss: 1.4052
2025-04-14 10:15:35,685 - INFO - Epoch 4/50 - Loss: 1.3890
2025-04-14 10:15:35,763 - INFO - Epoch 5/50 - Loss: 1.3782
2025-04-14 10:15:35,842 - INFO - Epoch 6/50 - Loss: 1.3709
2025-04-14 10:15:35,922 - INFO - Epoch 7/50 - Loss: 1.3652
2025-04-14 10:15:36,002 - INFO - Epoch 8/50 - Loss: 1.3596
2025-04-14 10:15:36,082 - INFO - Epoch 9/50 - Loss: 1.3562
2025-04-14 10:15:36,161 - INFO - Epoch 10/50 - Loss: 1.3500
2025-04-14 10:15:36,235 - INFO - Epoch 11/50 - Loss: 1.3441
2025-04-14 10:15:36,314 - INFO - Epoch 12/50 - Loss: 1.3332
2025-04-14 10:15:36,393 - INFO - Epoch 13/50 - Loss: 1.3219
2025-04-14 10:15:36,472 - INFO - Epoch 14/50 - Loss: 1.3048
2025-04-14 10:15:36,546 - INFO - Epoch 15/50 - Loss: 1.2805
2025-04-14 10:15:36,623 - INFO - Epoch 16/50 - Loss: 1.2501
2025-04-14 10:15:36,702 - INFO - Epoch 17/50 - Loss: 1.2162
2025-04-14 10:15:36,783 - INFO - Epoch 18/50 - Loss: 1.1714
2025-04-14 10:15:36,861 - INFO - Epoch 19/50 - Loss: 1.1396
2025-04-14 10:15:36,947 - INFO - Epoch 20/50 - Loss: 1.1507
2025-04-14 10:15:37,037 - INFO - Epoch 21/50 - Loss: 1.1303
2025-04-14 10:15:37,136 - INFO - Epoch 22/50 - Loss: 1.1403
2025-04-14 10:15:37,252 - INFO - Epoch 23/50 - Loss: 1.1816
2025-04-14 10:15:37,374 - INFO - Epoch 24/50 - Loss: 1.2050
2025-04-14 10:15:37,496 - INFO - Epoch 25/50 - Loss: 1.2090
2025-04-14 10:15:37,643 - INFO - Epoch 26/50 - Loss: 1.2969
2025-04-14 10:15:37,800 - INFO - Epoch 27/50 - Loss: 1.3325
2025-04-14 10:15:37,949 - INFO - Epoch 28/50 - Loss: 1.3515
2025-04-14 10:15:38,100 - INFO - Epoch 29/50 - Loss: 1.3871
2025-04-14 10:15:38,267 - INFO - Epoch 30/50 - Loss: 1.4608
2025-04-14 10:15:38,426 - INFO - Epoch 31/50 - Loss: 1.4587
2025-04-14 10:15:38,584 - INFO - Epoch 32/50 - Loss: 1.4947
2025-04-14 10:15:38,774 - INFO - Epoch 33/50 - Loss: 1.6002
2025-04-14 10:15:38,963 - INFO - Epoch 34/50 - Loss: 1.6222
2025-04-14 10:15:39,150 - INFO - Epoch 35/50 - Loss: 1.6257
2025-04-14 10:15:39,327 - INFO - Epoch 36/50 - Loss: 1.6360
2025-04-14 10:15:39,505 - INFO - Epoch 37/50 - Loss: 1.6582
2025-04-14 10:15:39,706 - INFO - Epoch 38/50 - Loss: 1.7220
2025-04-14 10:15:39,903 - INFO - Epoch 39/50 - Loss: 1.7403
2025-04-14 10:15:40,108 - INFO - Epoch 40/50 - Loss: 1.7707
2025-04-14 10:15:40,313 - INFO - Epoch 41/50 - Loss: 1.7855
2025-04-14 10:15:40,511 - INFO - Epoch 42/50 - Loss: 1.7723
2025-04-14 10:15:40,714 - INFO - Epoch 43/50 - Loss: 1.8017
2025-04-14 10:15:40,905 - INFO - Epoch 44/50 - Loss: 1.7864
2025-04-14 10:15:41,093 - INFO - Epoch 45/50 - Loss: 1.7742
2025-04-14 10:15:41,297 - INFO - Epoch 46/50 - Loss: 1.8257
2025-04-14 10:15:41,486 - INFO - Epoch 47/50 - Loss: 1.8224
2025-04-14 10:15:41,675 - INFO - Epoch 48/50 - Loss: 1.8239
2025-04-14 10:15:41,874 - INFO - Epoch 49/50 - Loss: 1.8483
2025-04-14 10:15:42,051 - INFO - Epoch 50/50 - Loss: 1.7980
2025-04-14 10:15:42,495 - INFO - Validation R² (Fold 3): 0.6155
2025-04-14 10:15:42,496 - INFO - 
Fold 4/4
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_x = torch.tensor(X[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  train_y = torch.tensor(y[train_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_x = torch.tensor(X[val_index], dtype=torch.float32).to(device)
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  val_y = torch.tensor(y[val_index], dtype=torch.float32).to(device)
2025-04-14 10:15:42,644 - INFO - Epoch 1/50 - Loss: 1.4027
2025-04-14 10:15:42,720 - INFO - Epoch 2/50 - Loss: 1.3871
2025-04-14 10:15:42,800 - INFO - Epoch 3/50 - Loss: 1.3768
2025-04-14 10:15:42,875 - INFO - Epoch 4/50 - Loss: 1.3691
2025-04-14 10:15:42,953 - INFO - Epoch 5/50 - Loss: 1.3654
2025-04-14 10:15:43,032 - INFO - Epoch 6/50 - Loss: 1.3604
2025-04-14 10:15:43,110 - INFO - Epoch 7/50 - Loss: 1.3555
2025-04-14 10:15:43,183 - INFO - Epoch 8/50 - Loss: 1.3502
2025-04-14 10:15:43,262 - INFO - Epoch 9/50 - Loss: 1.3399
2025-04-14 10:15:43,342 - INFO - Epoch 10/50 - Loss: 1.3292
2025-04-14 10:15:43,422 - INFO - Epoch 11/50 - Loss: 1.3113
2025-04-14 10:15:43,503 - INFO - Epoch 12/50 - Loss: 1.2860
2025-04-14 10:15:43,581 - INFO - Epoch 13/50 - Loss: 1.2494
2025-04-14 10:15:43,665 - INFO - Epoch 14/50 - Loss: 1.2106
2025-04-14 10:15:43,744 - INFO - Epoch 15/50 - Loss: 1.1609
2025-04-14 10:15:43,823 - INFO - Epoch 16/50 - Loss: 1.1291
2025-04-14 10:15:43,914 - INFO - Epoch 17/50 - Loss: 1.1400
2025-04-14 10:15:44,004 - INFO - Epoch 18/50 - Loss: 1.1226
2025-04-14 10:15:44,105 - INFO - Epoch 19/50 - Loss: 1.1624
2025-04-14 10:15:44,223 - INFO - Epoch 20/50 - Loss: 1.2044
2025-04-14 10:15:44,354 - INFO - Epoch 21/50 - Loss: 1.2542
2025-04-14 10:15:44,510 - INFO - Epoch 22/50 - Loss: 1.3501
2025-04-14 10:15:44,682 - INFO - Epoch 23/50 - Loss: 1.3874
2025-04-14 10:15:44,873 - INFO - Epoch 24/50 - Loss: 1.4749
2025-04-14 10:15:45,073 - INFO - Epoch 25/50 - Loss: 1.5443
2025-04-14 10:15:45,286 - INFO - Epoch 26/50 - Loss: 1.6170
2025-04-14 10:15:45,523 - INFO - Epoch 27/50 - Loss: 1.6810
2025-04-14 10:15:45,745 - INFO - Epoch 28/50 - Loss: 1.7127
2025-04-14 10:15:45,967 - INFO - Epoch 29/50 - Loss: 1.7423
2025-04-14 10:15:46,218 - INFO - Epoch 30/50 - Loss: 1.8359
2025-04-14 10:15:46,466 - INFO - Epoch 31/50 - Loss: 1.8402
2025-04-14 10:15:46,720 - INFO - Epoch 32/50 - Loss: 1.8844
2025-04-14 10:15:46,973 - INFO - Epoch 33/50 - Loss: 1.9061
2025-04-14 10:15:47,242 - INFO - Epoch 34/50 - Loss: 1.9455
2025-04-14 10:15:47,543 - INFO - Epoch 35/50 - Loss: 2.0003
2025-04-14 10:15:47,833 - INFO - Epoch 36/50 - Loss: 2.0183
2025-04-14 10:15:48,124 - INFO - Epoch 37/50 - Loss: 2.0237
2025-04-14 10:15:48,427 - INFO - Epoch 38/50 - Loss: 2.0743
2025-04-14 10:15:48,714 - INFO - Epoch 39/50 - Loss: 2.0416
2025-04-14 10:15:48,985 - INFO - Epoch 40/50 - Loss: 2.0423
2025-04-14 10:15:49,263 - INFO - Epoch 41/50 - Loss: 2.0658
2025-04-14 10:15:49,552 - INFO - Epoch 42/50 - Loss: 2.0819
2025-04-14 10:15:49,825 - INFO - Epoch 43/50 - Loss: 2.0546
2025-04-14 10:15:50,107 - INFO - Epoch 44/50 - Loss: 2.0962
2025-04-14 10:15:50,391 - INFO - Epoch 45/50 - Loss: 2.1003
2025-04-14 10:15:50,656 - INFO - Epoch 46/50 - Loss: 2.0707
2025-04-14 10:15:50,926 - INFO - Epoch 47/50 - Loss: 2.0626
2025-04-14 10:15:51,202 - INFO - Epoch 48/50 - Loss: 2.0785
2025-04-14 10:15:51,475 - INFO - Epoch 49/50 - Loss: 2.0953
2025-04-14 10:15:51,728 - INFO - Epoch 50/50 - Loss: 2.0540
/hpc/home/esl26/.conda/envs/wildfire-ai/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.2135075181722641 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.
  warnings.warn(
2025-04-14 10:15:52,310 - INFO - Validation R² (Fold 4): 0.4753
2025-04-14 10:15:52,311 - INFO - 
Average R² across folds: 0.5490
2025-04-14 10:15:52,311 - INFO - Best R² across folds: 0.6155
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:142: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  final_model = best_fold_model(torch.tensor(X, dtype=torch.float32).to(device),
/hpc/group/carlsonlab/esl26/uhi-deep-learning/generate_gp.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(y, dtype=torch.float32).to(device),
2025-04-14 10:15:52,313 - INFO - Generated 4488 points with 500m resolution
